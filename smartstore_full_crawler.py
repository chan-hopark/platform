#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ìƒí’ˆ ì •ë³´ ì™„ì „ í¬ë¡¤ëŸ¬
URLì—ì„œ productIdì™€ channelIdë¥¼ ì¶”ì¶œí•˜ì—¬ API í˜¸ì¶œ
"""

import requests
import json
import re
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import time

class SmartStoreCrawler:
    def __init__(self):
        self.session = requests.Session()
        self.setup_headers()
    
    def setup_headers(self):
        """ê¸°ë³¸ í—¤ë” ì„¤ì •"""
        self.session.headers.update({
            "accept": "application/json, text/plain, */*",
            "accept-encoding": "gzip, deflate, br, zstd",
            "accept-language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
            "x-client-version": "20251016170128",
        })
    
    def extract_product_id(self, url):
        """URLì—ì„œ productId ì¶”ì¶œ"""
        try:
            # /products/{ìˆ«ì} íŒ¨í„´ ë§¤ì¹­
            pattern = r'/products/(\d+)'
            match = re.search(pattern, url)
            if match:
                return match.group(1)
            return None
        except Exception as e:
            print(f"âŒ productId ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def extract_channel_id_from_html(self, url):
        """HTMLì—ì„œ channelId ì¶”ì¶œ"""
        try:
            print("ğŸ” HTMLì—ì„œ channelId ì¶”ì¶œ ì¤‘...")
            
            # HTML í˜ì´ì§€ ìš”ì²­
            response = self.session.get(url)
            if response.status_code != 200:
                print(f"âŒ HTML í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                return None
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ë°©ë²• 1: script íƒœê·¸ì—ì„œ channelId ì°¾ê¸°
            scripts = soup.find_all('script')
            for script in scripts:
                if script.string:
                    # /i/v2/channels/{channelId}/products/{productId} íŒ¨í„´ ì°¾ê¸°
                    pattern = r'/i/v2/channels/([^/]+)/products/(\d+)'
                    match = re.search(pattern, script.string)
                    if match:
                        channel_id = match.group(1)
                        print(f"âœ… script íƒœê·¸ì—ì„œ channelId ë°œê²¬: {channel_id}")
                        return channel_id
            
            # ë°©ë²• 2: meta íƒœê·¸ì—ì„œ ì°¾ê¸°
            meta_tags = soup.find_all('meta')
            for meta in meta_tags:
                content = meta.get('content', '')
                if 'channel' in content.lower():
                    pattern = r'channels/([^/]+)'
                    match = re.search(pattern, content)
                    if match:
                        channel_id = match.group(1)
                        print(f"âœ… meta íƒœê·¸ì—ì„œ channelId ë°œê²¬: {channel_id}")
                        return channel_id
            
            # ë°©ë²• 3: data ì†ì„±ì—ì„œ ì°¾ê¸°
            elements = soup.find_all(attrs={'data-channel-id': True})
            if elements:
                channel_id = elements[0]['data-channel-id']
                print(f"âœ… data ì†ì„±ì—ì„œ channelId ë°œê²¬: {channel_id}")
                return channel_id
            
            print("âš ï¸ HTMLì—ì„œ channelIdë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        except Exception as e:
            print(f"âŒ channelId ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_product_info(self, channel_id, product_id):
        """ìƒí’ˆ ì •ë³´ API í˜¸ì¶œ"""
        try:
            print("ğŸ›ï¸ ìƒí’ˆ ì •ë³´ API í˜¸ì¶œ ì¤‘...")
            
            api_url = f"https://smartstore.naver.com/i/v2/channels/{channel_id}/products/{product_id}?withWindow=false"
            response = self.session.get(api_url)
            
            if response.status_code == 200:
                data = response.json()
                return data.get('product', {})
            else:
                print(f"âŒ ìƒí’ˆ ì •ë³´ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
                return {}
                
        except Exception as e:
            print(f"âŒ ìƒí’ˆ ì •ë³´ API ì˜¤ë¥˜: {e}")
            return {}
    
    def get_reviews(self, product_id):
        """ë¦¬ë·° API í˜¸ì¶œ"""
        try:
            print("â­ ë¦¬ë·° ì •ë³´ API í˜¸ì¶œ ì¤‘...")
            
            # ë¦¬ë·° API URL (ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ íƒ­ì—ì„œ í™•ì¸í•œ endpoint ì‚¬ìš©)
            reviews_url = f"https://smartstore.naver.com/i/v2/reviews/{product_id}"
            params = {
                'page': 1,
                'size': 10,
                'sort': 'NEWEST'
            }
            
            response = self.session.get(reviews_url, params=params)
            
            if response.status_code == 200:
                data = response.json()
                return data.get('reviews', [])
            else:
                print(f"âŒ ë¦¬ë·° API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"âŒ ë¦¬ë·° API ì˜¤ë¥˜: {e}")
            return []
    
    def get_qnas(self, product_id):
        """Q&A API í˜¸ì¶œ"""
        try:
            print("â“ Q&A ì •ë³´ API í˜¸ì¶œ ì¤‘...")
            
            # Q&A API URL (ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ íƒ­ì—ì„œ í™•ì¸í•œ endpoint ì‚¬ìš©)
            qna_url = f"https://smartstore.naver.com/i/v2/qnas/{product_id}"
            params = {
                'page': 1,
                'size': 10,
                'sort': 'NEWEST'
            }
            
            response = self.session.get(qna_url, params=params)
            
            if response.status_code == 200:
                data = response.json()
                return data.get('qnas', [])
            else:
                print(f"âŒ Q&A API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"âŒ Q&A API ì˜¤ë¥˜: {e}")
            return []
    
    def format_price(self, price):
        """ê°€ê²© í¬ë§·íŒ…"""
        if isinstance(price, (int, float)):
            return f"{price:,}ì›"
        return str(price)
    
    def format_html_content(self, html_content):
        """HTML ë‚´ìš© í¬ë§·íŒ…"""
        if not html_content:
            return "ìƒì„¸ ì •ë³´ ì—†ìŒ"
        
        # HTML íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        soup = BeautifulSoup(html_content, 'html.parser')
        text = soup.get_text()
        
        # ë„ˆë¬´ ê¸´ ê²½ìš° ì˜ë¼ë‚´ê¸°
        if len(text) > 500:
            text = text[:500] + "..."
        
        return text
    
    def display_results(self, product_info, reviews, qnas):
        """ê²°ê³¼ í™”ë©´ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ›ï¸ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ìƒí’ˆ ì •ë³´")
        print("="*80)
        
        # ìƒí’ˆ ê¸°ë³¸ ì •ë³´
        print(f"\nğŸ“¦ ìƒí’ˆëª…: {product_info.get('productName', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ğŸ’° ê°€ê²©: {self.format_price(product_info.get('salePrice', 'ì •ë³´ ì—†ìŒ'))}")
        print(f"ğŸ·ï¸ ë¸Œëœë“œ: {product_info.get('brandName', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ğŸ“‚ ì¹´í…Œê³ ë¦¬: {product_info.get('categoryName', 'ì •ë³´ ì—†ìŒ')}")
        
        # ìƒì„¸ ì •ë³´
        detail_content = product_info.get('detailContent', '')
        if detail_content:
            print(f"\nğŸ“„ ìƒì„¸í˜ì´ì§€ ë‚´ìš©:")
            print("-" * 50)
            print(self.format_html_content(detail_content))
            print("-" * 50)
        else:
            print("\nğŸ“„ ìƒì„¸í˜ì´ì§€: ì •ë³´ ì—†ìŒ")
        
        # ë¦¬ë·° ì •ë³´
        if reviews:
            print(f"\nâ­ ë¦¬ë·° ({len(reviews)}ê°œ):")
            print("-" * 50)
            for i, review in enumerate(reviews[:10], 1):
                author = review.get('author', {}).get('name', 'ìµëª…')
                content = review.get('content', '')
                rating = review.get('rating', 0)
                date = review.get('createdAt', '')
                
                print(f"{i}. [{rating}ì ] {author}")
                print(f"   ë‚´ìš©: {content[:100]}{'...' if len(content) > 100 else ''}")
                print(f"   ë‚ ì§œ: {date}")
                print()
        else:
            print("\nâ­ ë¦¬ë·°: ì •ë³´ ì—†ìŒ")
        
        # Q&A ì •ë³´
        if qnas:
            print(f"\nâ“ Q&A ({len(qnas)}ê°œ):")
            print("-" * 50)
            for i, qna in enumerate(qnas[:10], 1):
                question = qna.get('question', '')
                answer = qna.get('answer', '')
                author = qna.get('author', {}).get('name', 'ìµëª…')
                date = qna.get('createdAt', '')
                
                print(f"{i}. Q: {question[:100]}{'...' if len(question) > 100 else ''}")
                if answer:
                    print(f"   A: {answer[:100]}{'...' if len(answer) > 100 else ''}")
                print(f"   ì‘ì„±ì: {author}, ë‚ ì§œ: {date}")
                print()
        else:
            print("\nâ“ Q&A: ì •ë³´ ì—†ìŒ")
        
        print("="*80)
    
    def crawl(self, url):
        """ë©”ì¸ í¬ë¡¤ë§ í•¨ìˆ˜"""
        try:
            print("ğŸš€ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ í¬ë¡¤ë§ ì‹œì‘...")
            print(f"ğŸ“ URL: {url}")
            
            # 1. productId ì¶”ì¶œ
            product_id = self.extract_product_id(url)
            if not product_id:
                print("âŒ productId ì¶”ì¶œ ì‹¤íŒ¨")
                return
            
            print(f"âœ… productId: {product_id}")
            
            # 2. channelId ì¶”ì¶œ
            channel_id = self.extract_channel_id_from_html(url)
            if not channel_id:
                print("âŒ channelId ì¶”ì¶œ ì‹¤íŒ¨")
                return
            
            print(f"âœ… channelId: {channel_id}")
            
            # 3. API í˜¸ì¶œ
            product_info = self.get_product_info(channel_id, product_id)
            reviews = self.get_reviews(product_id)
            qnas = self.get_qnas(product_id)
            
            # 4. ê²°ê³¼ ì¶œë ¥
            self.display_results(product_info, reviews, qnas)
            
            # 5. JSON íŒŒì¼ë¡œ ì €ì¥
            result = {
                'product': product_info,
                'reviews': reviews,
                'qnas': qnas,
                'crawled_at': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
            filename = f"smartstore_{product_id}_full_data.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ ì „ì²´ ë°ì´í„°ê°€ '{filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("="*80)
    print("ğŸ›ï¸ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì™„ì „ í¬ë¡¤ëŸ¬")
    print("="*80)
    print("ğŸ“ ì‚¬ìš©ë²•: ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ìƒí’ˆ URLì„ ì…ë ¥í•˜ì„¸ìš”")
    print("   ì˜ˆì‹œ: https://smartstore.naver.com/miliving/products/10037442277")
    print("="*80)
    
    # URL ì…ë ¥
    url = input("\nğŸ”— ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ìƒí’ˆ URLì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    
    if not url:
        print("âŒ URLì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    if not url.startswith("https://smartstore.naver.com/"):
        print("âŒ ì˜¬ë°”ë¥¸ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ URLì´ ì•„ë‹™ë‹ˆë‹¤.")
        return
    
    # í¬ë¡¤ë§ ì‹¤í–‰
    crawler = SmartStoreCrawler()
    crawler.crawl(url)
    
    print("\nâœ… í¬ë¡¤ë§ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
